{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: InferType: Executing module pass with opt level: 0\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "\n",
    "def get_demo_mod():\n",
    "    x = relay.var(\"x\", shape=(64, 64), dtype=\"float32\")\n",
    "    y = relay.var(\"y\", shape=(64, 64), dtype=\"float32\")\n",
    "    z = relay.var(\"z\", shape=(64, 64), dtype=\"float32\")\n",
    "    add = relay.add(x, y)\n",
    "    subtract = relay.subtract(add, z)\n",
    "    multiply = relay.multiply(subtract, z)\n",
    "\n",
    "    func = relay.Function([x, y, z], multiply)\n",
    "    mod = tvm.IRModule.from_expr(func)\n",
    "    mod = relay.transform.InferType()(mod)\n",
    "    return mod\n",
    "\n",
    "\n",
    "mod = get_demo_mod()\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass RemoveUnusedFunctions\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: RemoveUnusedFunctions: Executing module pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass ToBasicBlockNormalForm\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: ToBasicBlockNormalForm: Executing module pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass qnn.Legalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass QnnLegalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: QnnLegalize: Executing function pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: QnnLegalize: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: QnnLegalize: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: QnnLegalize: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass QnnCanonicalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: QnnCanonicalize: Executing function pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: QnnCanonicalize: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: QnnCanonicalize: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: QnnCanonicalize: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass Legalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: Legalize: Executing function pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: Legalize: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: Legalize: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: Legalize: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SimplifyInference\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SimplifyInference: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SimplifyInference: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SimplifyInference: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyInference: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass EliminateCommonSubexpr\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'EliminateCommonSubexpr'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CombineParallelConv2d\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CombineParallelConv2d'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CombineParallelDense\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CombineParallelDense'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CombineParallelBatchMatmul\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CombineParallelBatchMatmul'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldConstant\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FoldConstant: Executing function pass with opt level: 2\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FoldConstant: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FoldConstant: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FoldConstant: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldScaleAxis\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass BackwardFoldScaleAxis\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'BackwardFoldScaleAxis'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass ForwardFoldScaleAxis\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'ForwardFoldScaleAxis'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldConstant\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FoldConstant: Executing function pass with opt level: 2\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FoldConstant: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FoldConstant: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FoldConstant: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SimplifyExpr\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SimplifyExpr: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SimplifyExpr: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SimplifyExpr: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CanonicalizeCast\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CanonicalizeCast'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CanonicalizeOps\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CanonicalizeOps'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FlattenAtrousConv\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FlattenAtrousConv: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FlattenAtrousConv: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FlattenAtrousConv: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FlattenAtrousConv: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass InferType\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass AlterOpLayout\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'AlterOpLayout'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SimplifyExprPostAlterOp\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SimplifyExprPostAlterOp: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SimplifyExprPostAlterOp: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SimplifyExprPostAlterOp: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FastMath\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'FastMath'\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldConstant\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FoldConstant: Executing function pass with opt level: 2\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FoldConstant: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FoldConstant: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FoldConstant: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SplitArgs\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SplitArgs: Executing function pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SplitArgs: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SplitArgs: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SplitArgs: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass PlanDevices\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass PlanDevicesRewrite\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: PlanDevicesRewrite: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: PlanDevicesRewrite: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: PlanDevicesRewrite: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: PlanDevicesRewrite: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass PlanDevicesCore\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: PlanDevicesCore: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FuseOps\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FuseOps: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FuseOps: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FuseOps: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32], %p1: Tensor[(64, 64), float32], %p2: Tensor[(64, 64), float32], Primitive=1) -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1);\n",
      "    %1 = subtract(%0, %p2);\n",
      "    multiply(%1, %p2)\n",
      "  };\n",
      "  %2(%x, %y, %z)\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FuseOps: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InlineGlobals: Executing module pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: LabelOps: Executing function pass with opt level: 1\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: LabelOps: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1) -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: LabelOps: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1, hash=\"8b8bdf1c4ac262e5\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: LabelOps: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: AnnotateMemoryScope: Executing function pass with opt level: 2\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: AnnotateMemoryScope: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1, hash=\"8b8bdf1c4ac262e5\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: AnnotateMemoryScope: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1, hash=\"8b8bdf1c4ac262e5\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: AnnotateMemoryScope: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass RelayToTIRTargetHook\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: RelayToTIRTargetHook: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass LowerTE\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: LowerTE: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1, hash=\"8b8bdf1c4ac262e5\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'constant_memory_pools' = (nullptr)\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'main_func_info' = FunctionInfoNode(\n",
      "workspace_sizes={c -keys=cpu : 0},\n",
      "  io_sizes={c -keys=cpu : 65536},\n",
      "  constant_sizes={c -keys=cpu : 0},\n",
      "  tir_primfuncs={},\n",
      "  relay_primfuncs={c -keys=cpu : fn (%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1, hash=\"8b8bdf1c4ac262e5\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "} /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */\n",
      "})\n",
      "  'runtime' = cpp\n",
      "  'workspace_memory_pools' = (nullptr)\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectPrefetch\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.TextureFlatten\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlatten\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferShapeLegalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferStrideLegalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ThreadScopePropagate\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BufferBindUnwrapper\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ApplyLayoutTransforms\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageFlattener\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.AssertSimplifier\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerCrossThreadReduction\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerInitBlock\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.PlanAndUpdateBufferAllocationLocation\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ConvertBlocksToOpaque\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnifyThreadBinding\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.ManifestSharedMemoryLocalStage\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CompactBufferAllocation\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerAutoCopy\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerMatchBuffer\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectSoftwarePipeline\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LowerOpaqueBlock\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.FlattenBuffer\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.BF16ComputeLegalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.NarrowDataType\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.LoopPartition\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.VectorizeLoop\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectVirtualThread\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InjectDoubleBuffer\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.StorageRewrite\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.UnrollLoop\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RenormalizeSplitPattern\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"x\", \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"y\", \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"z\", \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"tvm_op\", \n",
      "      \"name\": \"tvmgen_default_fused_add_subtract_multiply\", \n",
      "      \"attrs\": {\n",
      "        \"num_outputs\": \"1\", \n",
      "        \"num_inputs\": \"3\", \n",
      "        \"flatten_data\": \"0\", \n",
      "        \"func_name\": \"tvmgen_default_fused_add_subtract_multiply\", \n",
      "        \"hash\": \"8b8bdf1c4ac262e5\"\n",
      "      }, \n",
      "      \"inputs\": [\n",
      "        [\n",
      "          0, \n",
      "          0, \n",
      "          0\n",
      "        ], \n",
      "        [\n",
      "          1, \n",
      "          0, \n",
      "          0\n",
      "        ], \n",
      "        [\n",
      "          2, \n",
      "          0, \n",
      "          0\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  ], \n",
      "  \"arg_nodes\": [0, 1, 2], \n",
      "  \"heads\": [\n",
      "    [\n",
      "      3, \n",
      "      0, \n",
      "      0\n",
      "    ]\n",
      "  ], \n",
      "  \"attrs\": {\n",
      "    \"dltype\": [\n",
      "      \"list_str\", \n",
      "      [\n",
      "        \"float32\", \n",
      "        \"float32\", \n",
      "        \"float32\", \n",
      "        \"float32\"\n",
      "      ]\n",
      "    ], \n",
      "    \"device_index\": [\n",
      "      \"list_int\", \n",
      "      [1, 1, 1, 1]\n",
      "    ], \n",
      "    \"storage_id\": [\n",
      "      \"list_int\", \n",
      "      [0, 1, 2, 3]\n",
      "    ], \n",
      "    \"shape\": [\n",
      "      \"list_shape\", \n",
      "      [\n",
      "        [64, 64], \n",
      "        [64, 64], \n",
      "        [64, 64], \n",
      "        [64, 64]\n",
      "      ]\n",
      "    ]\n",
      "  }, \n",
      "  \"node_row_ptr\": [0, 1, 2, 3, 4]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RewriteUnsafeSelect\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.HoistIfThenElse\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.InsertHoistIfThenElse\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.Simplify\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.RemoveNoOp\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Running pass tir.CommonSubexprElimTIR\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %0 = (%x, %y, %z);\n",
      "  call_lowered(@tvmgen_default_fused_add_subtract_multiply, %0, metadata={\"relay_attrs\"={__dict__={\"Primitive\"=1, \"hash\"=\"8b8bdf1c4ac262e5\"}}, \"all_prim_fn_vars\"=['tvmgen_default_fused_add_subtract_multiply']})\n",
      "}\n",
      "attributes {\n",
      "  'constant_memory_pools' = (nullptr)\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'main_func_info' = FunctionInfoNode(\n",
      "workspace_sizes={c -keys=cpu : 0},\n",
      "  io_sizes={c -keys=cpu : 65536},\n",
      "  constant_sizes={c -keys=cpu : 0},\n",
      "  tir_primfuncs={},\n",
      "  relay_primfuncs={c -keys=cpu : fn (%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"b9d61c9208ebb35e\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3d714b0, kind='c', keys={'cpu'}, host=Target(id=2d23bf0, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%p0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %p2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Primitive=1, hash=\"8b8bdf1c4ac262e5\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%p0, %p1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %p2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %p2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "} /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */\n",
      "})\n",
      "  'runtime' = cpp\n",
      "  'workspace_memory_pools' = (nullptr)\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass InferType\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass tir.ExtractPrimFuncConstants\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: tir.ExtractPrimFuncConstants: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.calculate_allocated_bytes\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: tir.calculate_allocated_bytes: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerVtcmAlloc\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.BindTarget\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.VerifyMemory\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: tir.VerifyMemory: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.AnnotateEntryFunc\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.ThreadSync\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.ThreadSync\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.MergeDynamicSharedMemoryAllocations\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.ThreadSync\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.InferFragment\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerThreadAllreduce\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.MakePackedAPI\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: tir.MakePackedAPI: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.BF16StorageLegalize\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.SplitHostDevice\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: tir.SplitHostDevice: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: tir.SplitHostDevice: tir.ConvertSSA: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.Filter\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.BindTarget\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerTVMBuiltin\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerCustomDatatypes\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerIntrin\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerDeviceStorageAccessInfo\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.CombineContextCall\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.Filter\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.BindTarget\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerWarpMemory\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.Simplify\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerCustomDatatypes\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerDeviceStorageAccessInfo\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass tir.LowerIntrin\n",
      "/tmp/ipykernel_30182/48896817.py:2: DeprecationWarning: legacy graph executor behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_executor.GraphModule for the  new recommended usage.\n",
      "  graph, lib, params = relay.build(mod, target=\"c\", params=None)\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=2):\n",
    "    graph, lib, params = relay.build(mod, target=\"c\", params=None)\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// tvm target: c -keys=cpu \n",
      "#define TVM_EXPORTS\n",
      "#include \"tvm/runtime/c_runtime_api.h\"\n",
      "#include \"tvm/runtime/c_backend_api.h\"\n",
      "#include <math.h>\n",
      "#include <stdbool.h>\n",
      "#ifdef __cplusplus\n",
      "extern \"C\"\n",
      "#endif\n",
      "TVM_DLL int32_t tvmgen_default_fused_add_subtract_multiply(void* args, int32_t* arg_type_ids, int32_t num_args, void* out_ret_value, int32_t* out_ret_tcode, void* resource_handle) {\n",
      "  void* arg_p0 = (((TVMValue*)args)[0].v_handle);\n",
      "  int32_t arg_p0_code = arg_type_ids[0];\n",
      "  void* arg_p1 = (((TVMValue*)args)[1].v_handle);\n",
      "  int32_t arg_p1_code = arg_type_ids[1];\n",
      "  void* arg_p2 = (((TVMValue*)args)[2].v_handle);\n",
      "  int32_t arg_p2_code = arg_type_ids[2];\n",
      "  void* arg_T_multiply = (((TVMValue*)args)[3].v_handle);\n",
      "  int32_t arg_T_multiply_code = arg_type_ids[3];\n",
      "  void* p0 = (((DLTensor*)arg_p0)[0].data);\n",
      "  void* arg_p0_shape = (((DLTensor*)arg_p0)[0].shape);\n",
      "  void* arg_p0_strides = (((DLTensor*)arg_p0)[0].strides);\n",
      "  int32_t dev_id = (((DLTensor*)arg_p0)[0].device.device_id);\n",
      "  void* p1 = (((DLTensor*)arg_p1)[0].data);\n",
      "  void* arg_p1_shape = (((DLTensor*)arg_p1)[0].shape);\n",
      "  void* arg_p1_strides = (((DLTensor*)arg_p1)[0].strides);\n",
      "  void* p2 = (((DLTensor*)arg_p2)[0].data);\n",
      "  void* arg_p2_shape = (((DLTensor*)arg_p2)[0].shape);\n",
      "  void* arg_p2_strides = (((DLTensor*)arg_p2)[0].strides);\n",
      "  void* T_multiply = (((DLTensor*)arg_T_multiply)[0].data);\n",
      "  void* arg_T_multiply_shape = (((DLTensor*)arg_T_multiply)[0].shape);\n",
      "  void* arg_T_multiply_strides = (((DLTensor*)arg_T_multiply)[0].strides);\n",
      "  if (!(arg_p0_strides == NULL)) {\n",
      "  }\n",
      "  if (!(arg_p1_strides == NULL)) {\n",
      "  }\n",
      "  if (!(arg_p2_strides == NULL)) {\n",
      "  }\n",
      "  if (!(arg_T_multiply_strides == NULL)) {\n",
      "  }\n",
      "  for (int32_t ax0 = 0; ax0 < 64; ++ax0) {\n",
      "    for (int32_t ax1_outer = 0; ax1_outer < 4; ++ax1_outer) {\n",
      "      int32_t cse_var_1 = ((ax0 * 64) + (ax1_outer * 16));\n",
      "      int32_t16 v_ = int32_t16((cse_var_1)+(1*0), (cse_var_1)+(1*1), (cse_var_1)+(1*2), (cse_var_1)+(1*3), (cse_var_1)+(1*4), (cse_var_1)+(1*5), (cse_var_1)+(1*6), (cse_var_1)+(1*7), (cse_var_1)+(1*8), (cse_var_1)+(1*9), (cse_var_1)+(1*10), (cse_var_1)+(1*11), (cse_var_1)+(1*12), (cse_var_1)+(1*13), (cse_var_1)+(1*14), (cse_var_1)+(1*15));\n",
      "      *(float16*)(((float*)T_multiply) + cse_var_1) = ((((float16(((float*)p0)[v_.s0],((float*)p0)[v_.s1],((float*)p0)[v_.s2],((float*)p0)[v_.s3],((float*)p0)[v_.s4],((float*)p0)[v_.s5],((float*)p0)[v_.s6],((float*)p0)[v_.s7],((float*)p0)[v_.s8],((float*)p0)[v_.s9],((float*)p0)[v_.sa],((float*)p0)[v_.sb],((float*)p0)[v_.sc],((float*)p0)[v_.sd],((float*)p0)[v_.se],((float*)p0)[v_.sf])) + (float16(((float*)p1)[v_.s0],((float*)p1)[v_.s1],((float*)p1)[v_.s2],((float*)p1)[v_.s3],((float*)p1)[v_.s4],((float*)p1)[v_.s5],((float*)p1)[v_.s6],((float*)p1)[v_.s7],((float*)p1)[v_.s8],((float*)p1)[v_.s9],((float*)p1)[v_.sa],((float*)p1)[v_.sb],((float*)p1)[v_.sc],((float*)p1)[v_.sd],((float*)p1)[v_.se],((float*)p1)[v_.sf]))) - (float16(((float*)p2)[v_.s0],((float*)p2)[v_.s1],((float*)p2)[v_.s2],((float*)p2)[v_.s3],((float*)p2)[v_.s4],((float*)p2)[v_.s5],((float*)p2)[v_.s6],((float*)p2)[v_.s7],((float*)p2)[v_.s8],((float*)p2)[v_.s9],((float*)p2)[v_.sa],((float*)p2)[v_.sb],((float*)p2)[v_.sc],((float*)p2)[v_.sd],((float*)p2)[v_.se],((float*)p2)[v_.sf]))) * (float16(((float*)p2)[v_.s0],((float*)p2)[v_.s1],((float*)p2)[v_.s2],((float*)p2)[v_.s3],((float*)p2)[v_.s4],((float*)p2)[v_.s5],((float*)p2)[v_.s6],((float*)p2)[v_.s7],((float*)p2)[v_.s8],((float*)p2)[v_.s9],((float*)p2)[v_.sa],((float*)p2)[v_.sb],((float*)p2)[v_.sc],((float*)p2)[v_.sd],((float*)p2)[v_.se],((float*)p2)[v_.sf])));\n",
      "    }\n",
      "  }\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "// CodegenC: NOTE: Auto-generated entry function\n",
      "#ifdef __cplusplus\n",
      "extern \"C\"\n",
      "#endif\n",
      "TVM_DLL int32_t __tvm_main__(void* args, int* arg_type_ids, int num_args, void* out_ret_value, int* out_ret_tcode, void* resource_handle) {\n",
      "  return tvmgen_default_fused_add_subtract_multiply(args, arg_type_ids, num_args, out_ret_value, out_ret_tcode, resource_handle);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lib.get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip because PIM codegen is not available\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass AnnotateTargetFunc\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: AnnotateTargetFunc: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: AnnotateTargetFunc: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%x, %y) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %z) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: AnnotateTargetFunc: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = annotation.compiler_begin(%x, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = annotation.compiler_begin(%y, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %2 = add(%0, %1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %3 = annotation.compiler_end(%2, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %4 = annotation.compiler_begin(%3, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %5 = annotation.compiler_begin(%z, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %6 = subtract(%4, %5) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %7 = annotation.compiler_end(%6, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %8 = annotation.compiler_begin(%7, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %9 = annotation.compiler_begin(%z, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %10 = multiply(%8, %9) /* ty=Tensor[(64, 64), float32] */;\n",
      "  annotation.compiler_end(%10, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: AnnotateTargetFunc: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass InferType\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass MergeCompilerRegions\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: MergeCompilerRegions: Executing function pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: MergeCompilerRegions: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = annotation.compiler_begin(%x, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = annotation.compiler_begin(%y, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %2 = add(%0, %1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %3 = annotation.compiler_end(%2, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %4 = annotation.compiler_begin(%3, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %5 = annotation.compiler_begin(%z, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %6 = subtract(%4, %5) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %7 = annotation.compiler_end(%6, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %8 = annotation.compiler_begin(%7, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %9 = annotation.compiler_begin(%z, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %10 = multiply(%8, %9) /* ty=Tensor[(64, 64), float32] */;\n",
      "  annotation.compiler_end(%10, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: MergeCompilerRegions: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  %0 = annotation.compiler_begin(%x, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = annotation.compiler_begin(%y, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %2 = add(%0, %1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %3 = annotation.compiler_begin(%z, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %4 = subtract(%2, %3) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %5 = annotation.compiler_begin(%z, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */;\n",
      "  %6 = multiply(%4, %5) /* ty=Tensor[(64, 64), float32] */;\n",
      "  annotation.compiler_end(%6, compiler=\"pim\") /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: MergeCompilerRegions: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass InferType\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass FlattenNestedTuples\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: FlattenNestedTuples: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: FlattenNestedTuples: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass RemoveDefaultAnnotations\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: RemoveDefaultAnnotations: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: RemoveDefaultAnnotations: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass PartitionGraph\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: PartitionGraph: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: PartitionGraph: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: PartitionGraph: InferType: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass NameMangleExtFuncs\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: NameMangleExtFuncs: Executing module pass with opt level: 0\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Running pass InferType\n",
      "[19:05:02] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: InferType: Executing module pass with opt level: 0\n"
     ]
    }
   ],
   "source": [
    "from tvm.relay import transform\n",
    "\n",
    "if not tvm.get_global_func(\"relay.ext.PIMCompiler\", True):\n",
    "    print(\"skip because PIM codegen is not available\")\n",
    "else:\n",
    "    print(\"PIM codegen is now available\")\n",
    "\n",
    "mod = get_demo_mod()\n",
    "mod = relay.transform.AnnotateTarget(\"pim\")(mod)\n",
    "mod = transform.MergeCompilerRegions()(mod)\n",
    "mod = relay.transform.PartitionGraph()(mod)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass RemoveUnusedFunctions\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: RemoveUnusedFunctions: Executing module pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass ToBasicBlockNormalForm\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: ToBasicBlockNormalForm: Executing module pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass qnn.Legalize\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass QnnLegalize\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: QnnLegalize: Executing function pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: QnnLegalize: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: QnnLegalize: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: QnnLegalize: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass QnnCanonicalize\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: QnnCanonicalize: Executing function pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: QnnCanonicalize: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: QnnCanonicalize: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: QnnCanonicalize: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass Legalize\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: Legalize: Executing function pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: Legalize: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: Legalize: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: Legalize: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SimplifyInference\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SimplifyInference: Executing function pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SimplifyInference: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SimplifyInference: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyInference: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass EliminateCommonSubexpr\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'EliminateCommonSubexpr'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CombineParallelConv2d\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CombineParallelConv2d'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CombineParallelDense\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CombineParallelDense'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CombineParallelBatchMatmul\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CombineParallelBatchMatmul'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldConstant\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FoldConstant: Executing function pass with opt level: 2\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FoldConstant: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FoldConstant: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FoldConstant: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldScaleAxis\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass BackwardFoldScaleAxis\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'BackwardFoldScaleAxis'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass ForwardFoldScaleAxis\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'ForwardFoldScaleAxis'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldConstant\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FoldConstant: Executing function pass with opt level: 2\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FoldConstant: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FoldConstant: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FoldConstant: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SimplifyExpr\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SimplifyExpr: Executing function pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SimplifyExpr: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SimplifyExpr: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExpr: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CanonicalizeCast\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CanonicalizeCast'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass CanonicalizeOps\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'CanonicalizeOps'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FlattenAtrousConv\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FlattenAtrousConv: Executing function pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FlattenAtrousConv: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FlattenAtrousConv: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FlattenAtrousConv: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass InferType\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass AlterOpLayout\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'AlterOpLayout'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SimplifyExprPostAlterOp\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SimplifyExprPostAlterOp: Executing function pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SimplifyExprPostAlterOp: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: PatternRewriter: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SimplifyExprPostAlterOp: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SimplifyExprPostAlterOp: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FastMath\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:447: Build: skipping disabled pass 'FastMath'\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FoldConstant\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FoldConstant: Executing function pass with opt level: 2\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FoldConstant: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FoldConstant: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FoldConstant: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass SplitArgs\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: SplitArgs: Executing function pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: SplitArgs: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: SplitArgs: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: SplitArgs: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass PlanDevices\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass PlanDevicesRewrite\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: PlanDevicesRewrite: Executing function pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: PlanDevicesRewrite: Input module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: PlanDevicesRewrite: Output module:\n",
      "def @main(%x: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0]) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: PlanDevicesRewrite: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass PlanDevicesCore\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: PlanDevicesCore: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: Running pass FuseOps\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: FuseOps: Executing function pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: FuseOps: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: FuseOps: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  @tvmgen_default_pim_main_0(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_pim_main_0(%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "  %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "  %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "  multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: FuseOps: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InlineGlobals: Executing module pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: LabelOps: Executing function pass with opt level: 1\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: LabelOps: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: LabelOps: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, hash=\"e01de14bc50c0802\", Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: LabelOps: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: AnnotateMemoryScope: Executing function pass with opt level: 2\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: AnnotateMemoryScope: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, hash=\"e01de14bc50c0802\", Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: AnnotateMemoryScope: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, hash=\"e01de14bc50c0802\", Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'runtime' = cpp\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: AnnotateMemoryScope: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass RelayToTIRTargetHook\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: RelayToTIRTargetHook: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass LowerTE\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: LowerTE: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:124: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Executing function pass with opt level: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";\n",
      "#include <cstdint>\n",
      "#include <iostream>\n",
      "#include <cstdlib>\n",
      "#include <stdio.h>\n",
      "#include <cstring>\n",
      "#include <tvm/runtime/c_runtime_api.h>\n",
      "#include <tvm/runtime/packed_func.h>\n",
      "#include <dlpack/dlpack.h>\n",
      "#include <dnnl/dnnl_kernel.h>\n",
      "using namespace tvm::runtime;\n",
      "using namespace tvm::runtime::contrib;\n",
      "\n",
      "\n",
      "  #define CSOURCE_BINARY_OP_1D(p_ID_, p_OP_, p_DIM1_)       \\\n",
      "    extern \"C\" void p_ID_(float* a, float* b, float* out) { \\\n",
      "      for (int64_t i = 0; i < p_DIM1_; ++i) {               \\\n",
      "        out[i] = a[i] p_OP_ b[i];                           \\\n",
      "      }                                                     \\\n",
      "    }\n",
      "\n",
      "  #define CSOURCE_BINARY_OP_2D(p_ID_, p_OP_, p_DIM1_, p_DIM2_)  \\\n",
      "    extern \"C\" void p_ID_(float* a, float* b, float* out) {     \\\n",
      "      for (int64_t i = 0; i < p_DIM1_; ++i) {                   \\\n",
      "        for (int64_t j = 0; j < p_DIM2_; ++j) {                 \\\n",
      "          int64_t k = i * p_DIM2_ + j;                          \\\n",
      "          out[k] = a[k] p_OP_ b[k];                             \\\n",
      "        }                                                       \\\n",
      "      }                                                         \\\n",
      "    }\n",
      "  \n",
      "\n",
      "CSOURCE_BINARY_OP_2D(tvmgen_default_pim_main_0_0, *, 64, 64);\n",
      "CSOURCE_BINARY_OP_2D(tvmgen_default_pim_main_0_1, -, 64, 64);\n",
      "CSOURCE_BINARY_OP_2D(tvmgen_default_pim_main_0_2, +, 64, 64);\n",
      "#ifdef __cplusplus\n",
      "tvm::runtime::Array<tvm::runtime::NDArray> tvmgen_default_pim_main_0_consts;\n",
      "\n",
      "#endif\n",
      "void tvmgen_default_pim_main_0_(float* pim_0_i0, float* pim_0_i1, float* pim_0_i2, float* out0) {\n",
      "  float* buf_0 = (float*)std::malloc(4 * 4096);\n",
      "  float* buf_1 = (float*)std::malloc(4 * 4096);\n",
      "  float* buf_2 = (float*)std::malloc(4 * 4096);\n",
      "\n",
      "  tvmgen_default_pim_main_0_2(pim_0_i0, pim_0_i1, buf_0);\n",
      "  tvmgen_default_pim_main_0_1(buf_0, pim_0_i2, buf_1);\n",
      "  tvmgen_default_pim_main_0_0(buf_1, pim_0_i2, buf_2);\n",
      "  memcpy(out0, buf_2, 4 * 4096);\n",
      "  free(buf_0);\n",
      "  free(buf_1);\n",
      "  free(buf_2);\n",
      "}\n",
      "\n",
      "int tvmgen_default_pim_main_0_wrapper_(DLTensor* arg0,\n",
      "\tDLTensor* arg1,\n",
      "\tDLTensor* arg2,\n",
      "\tDLTensor* out0) {\n",
      "  tvmgen_default_pim_main_0_((float*)(arg0->data),\n",
      "  (float*)(arg1->data),\n",
      "  (float*)(arg2->data),\n",
      "  (float*)(out0->data));\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "#ifdef __cplusplus\n",
      "extern \"C\" {\n",
      "#endif\n",
      "TVM_DLL int32_t tvmgen_default_pim_main_0(TVMValue* args, int* type_code, int num_args, TVMValue* out_value, int* out_type_code) {\n",
      "  DLTensor* arg0 = (DLTensor*)(((TVMValue*)args)[0].v_handle);\n",
      "  DLTensor* arg1 = (DLTensor*)(((TVMValue*)args)[1].v_handle);\n",
      "  DLTensor* arg2 = (DLTensor*)(((TVMValue*)args)[2].v_handle);\n",
      "  DLTensor* ret3 = (DLTensor*)(((TVMValue*)args)[3].v_handle);\n",
      "  tvmgen_default_pim_main_0_wrapper_(arg0,arg1,arg2,ret3);\n",
      "  return 0;\n",
      "}\n",
      "#ifdef __cplusplus\n",
      "}\n",
      "#endif\n",
      "#ifdef __cplusplus\n",
      "int tvmgen_default_pim_main_0_init_wrapper_(tvm::runtime::Array<tvm::runtime::NDArray> arr) {\n",
      "  tvmgen_default_pim_main_0_consts = arr;\n",
      "return 0;\n",
      "}\n",
      "\n",
      "TVM_DLL_EXPORT_TYPED_FUNC(__init_tvmgen_default_pim_main_0, tvmgen_default_pim_main_0_init_wrapper_);\n",
      "\n",
      "#endif\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:125: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Input module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, hash=\"e01de14bc50c0802\", Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "}\n",
      "attributes {\n",
      "  'constant_memory_pools' = (nullptr)\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'main_func_info' = FunctionInfoNode(\n",
      "workspace_sizes={c -keys=cpu : 0},\n",
      "  io_sizes={c -keys=cpu : 65536},\n",
      "  constant_sizes={c -keys=cpu : 0},\n",
      "  tir_primfuncs={},\n",
      "  relay_primfuncs={c -keys=cpu : fn (%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, hash=\"e01de14bc50c0802\", Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "} /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */\n",
      "})\n",
      "  'runtime' = cpp\n",
      "  'workspace_memory_pools' = (nullptr)\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/relay/ir/transform.cc:148: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: Output module:\n",
      "def @main(%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %0 = (%x, %y, %z);\n",
      "  call_lowered(@tvmgen_default_pim_main_0, %0, metadata={\"relay_attrs\"={__dict__={\"Compiler\"=\"pim\", \"Primitive\"=1, \"hash\"=\"e01de14bc50c0802\", \"Inline\"=1, \"global_symbol\"=\"tvmgen_default_pim_main_0\"}}, \"all_prim_fn_vars\"=[]})\n",
      "}\n",
      "attributes {\n",
      "  'constant_memory_pools' = (nullptr)\n",
      "  'executor' = graph{\"link-params\": T.bool(False)}\n",
      "  'main_func_info' = FunctionInfoNode(\n",
      "workspace_sizes={c -keys=cpu : 0},\n",
      "  io_sizes={c -keys=cpu : 65536},\n",
      "  constant_sizes={c -keys=cpu : 0},\n",
      "  tir_primfuncs={},\n",
      "  relay_primfuncs={c -keys=cpu : fn (%x {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %y {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %z {virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))}: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, executor=meta[Executor][0], runtime=meta[Runtime][0], hash=\"7202c58eea5f7051\", virtual_device=VirtualDevice(device_type=1, virtual_device_id=0, target=Target(id=3e3ec00, kind='c', keys={'cpu'}, host=Target(id=35be740, kind='c', keys={'cpu'})))) -> Tensor[(64, 64), float32] {\n",
      "  %2 = fn (%pim_0_i0: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i1: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, %pim_0_i2: Tensor[(64, 64), float32] /* ty=Tensor[(64, 64), float32] */, Compiler=\"pim\", Primitive=1, hash=\"e01de14bc50c0802\", Inline=1, global_symbol=\"tvmgen_default_pim_main_0\") -> Tensor[(64, 64), float32] {\n",
      "    %0 = add(%pim_0_i0, %pim_0_i1) /* ty=Tensor[(64, 64), float32] */;\n",
      "    %1 = subtract(%0, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */;\n",
      "    multiply(%1, %pim_0_i2) /* ty=Tensor[(64, 64), float32] */\n",
      "  } /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */;\n",
      "  %2(%x, %y, %z) /* ty=Tensor[(64, 64), float32] */\n",
      "} /* ty=fn (Tensor[(64, 64), float32], Tensor[(64, 64), float32], Tensor[(64, 64), float32]) -> Tensor[(64, 64), float32] */\n",
      "})\n",
      "  'runtime' = cpp\n",
      "  'workspace_memory_pools' = (nullptr)\n",
      "}\n",
      "\n",
      "\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: LowerTE: LowerTensorExpr: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass InferType\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: InferType: Executing module pass with opt level: 0\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:443: Build: GraphExecutorCodegen: Running pass tir.ExtractPrimFuncConstants\n",
      "[19:05:03] /home/qzylalala/work_space/tvm/src/ir/transform.cc:382: Build: GraphExecutorCodegen: tir.ExtractPrimFuncConstants: Executing module pass with opt level: 0\n",
      "/tmp/ipykernel_30182/1512527356.py:2: DeprecationWarning: legacy graph executor behavior of producing json / lib / params will be removed in the next release. Please see documents of tvm.contrib.graph_executor.GraphModule for the  new recommended usage.\n",
      "  graph, lib, params = relay.build(mod, target=\"c\", params=None)\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=2):\n",
    "    graph, lib, params = relay.build(mod, target=\"c\", params=None)\n",
    "\n",
    "# lib.export_library(\"libpim.so\")\n",
    "print(lib.imported_modules[0].get_source())\n",
    "print(lib.imported_modules[1].get_source())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
